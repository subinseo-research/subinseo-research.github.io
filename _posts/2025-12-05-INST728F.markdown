---
layout: post
title:  "MindFlex AI"
date:   2025-12-5 18:05:55 +0300
image:  post_11_0.png
tags:   Human-Centered System_Design    
---

 <h1>Overview</h1>
 <br><br>

<div style="text-align: justify;">
<h3>üîçProject Context</h3>
<p>MindFlex AI is an adaotive information system powered by gnerative AI models, which can provide personalized information and adjust their UI based on users' queries.  Therefore, it is an intelligent system in which AI reads the emotional state of the human user and responds flexibly accordingly.
<br><br>
Jensen Huang, the CEO of NVIDIA,<a href="https://www.instagram.com/reel/DR4QwDcDIVd/" target="_blank"> describes AI as the easiest tool</a> in human history and one that can help realize equity. I agree with this to some extent. More precisely, I believe that while AI is not yet such a tool, it holds that potential. Users can interact with AI through a simple chat in their preferred language, which has contributed to the rapid popularity of models like ChatGPT and Gemini. However, despite the wide diversity in users' backgrounds and contexts, these general-purpose AI models provide the same environment to all users. As a result, the quality of AI responses can vary significantly depending on users' literacy and metacognitive abilities. To address this disparity, I propose an adaptive system that reflects users' context with the UI components. 
<br><br>
This project was proposed in the course INST728F in 2025 Fall semester, led by Professor Tom Brinck at the University of Maryland, and the primary focus was to implement these ideas through UX/UI design.
</p> 
</div>

---
<div style="text-align: justify;">
    <br>
    <h3>‚ùìProblem</h3>
    Most AI systems have been optimized primarily for <u>accurcay-related metrics</u> such as F-meaurse. However, real human information-seeking behavior is far more influenced by the context in which the system is used and by psychological factors such as cognitive load and trust calibration. 
    <br><br>
    Misuse of general-purpose AI can lead to truly dangerous consequences. <a href="https://www.youtube.com/watch?v=jBnJlwcnOBI" target="_blank"> In August 2025, there was a case in which a student died by suicide after interacting with ChatGPT </a>. This incident occurred, in part, because generative AIs like ChatGPT are generally designed to respond supportively to users regardless of the purpose of use. However, this issue cannot simply be dismissed as an individual's poor judgment. To design safer and more equitable information systems, we must confront and address these challenges directly.
    <br><br>
    Therefore, this project explores what kinds of design are needed to prevent misuse and build a safer information system.
    <br><br>
    <div class="notice--yellow">
    "How can I reduce users' <strong>cognitive, emotional, and informational misuse</strong> in general-purpose AI?"
    </div>
    <br>
</div>

---
<h3>üéØDesogm Goals and Final Designs</h3>

<br>
<br>
<strong>Design Goal 1Ô∏è‚É£: Support for various modes tailored to users needs</strong>
![Mainstream GIF](/images/Post_11/MainStream.gif)
* Support for five distinct modes:<br> 
            research, development, creation, business, and counseling
* The settings page allows for more specific customization: <br>
            preferred sources, citation style, level of alerts 
<br>

![Mainstream2](/images/Post_11/Mainstream2.gif)
Users can choose the best-fit mode through conversation
<br>

![Mainstream3](/images/Post_11/Mainstream3.gif)
If a user accidentally uses the wrong mode during a conversation, the system detects it and suggests switching to the appropriate mode.

<br>
<strong>Design Goal 2Ô∏è‚É£: Guide users to identify their specific information needs</strong>

![Function1 GIF](/images/Post_11/Function1.gif)
If a user submits an overly broad prompt, the system asks follow-up questions to better serve the user's ultimate needs. However, <u>to prevent users from feeling burdened by answering these questions, the design allows for quick and easy responses through clickable options.</u>

<br>
<strong>Design Goal 3Ô∏è‚É£: Build user trust in sources</strong>

![Function2 GIF](/images/Post_11/Function2.gif)
Many recent generative AI services already provide source citations. However, I added a citation type selection button so that users can easily copy and view citations at once, while also presenting an overall credibility message to encourage users' metacognitive judgment.
<br><br>
For credibility message, 
* If the number of sources in a generated response is between 0 and 2, the system issues a warning that the content may be dangerous üî¥.
* If the number of sources is between 3 and 5, the system issues a warning that the information may be insufficient üü°.
* If the number of sources is 6 or more, the system indicates that the information is safe üü¢.

<br>
<strong>Design Goal 4Ô∏è‚É£: Detect Overtrust</strong>

![Function3 GIF](/images/Post_11/Function3.gif)

When the system detects that a user overly relies on AI, it intentionally disrupts the flow by displaying a warning message instead of responding in the chat window.


---
<h1>Discovery</h1>
<br><br>

<div align="center">
  <img src="/images/Post_11/interview.png" alt="interview"> <br>
  4 Interviews 
</div>
<br>

<h3>Users struggle with‚Ä¶</h3>
* difficulty determining the credibility of AI-generated information
* inconsistent information quality depending on the mode or topic
* fear of over-relying on AI for decisions without understanding how answers are generated

<h3>Users want to‚Ä¶</h3>
* receive clear, transparent, and context-appropriate validation for each response
* get citations in their preferred format (APA, MLA, Chicago, etc.)
* quickly scan source credibility without opening external tools

<h3>What are the product goals?</h3>
Following user research, we developed a persona grounded in the collected data and insights. 

![User1](/images/Post_11/User1.png)

Based on this initial concept of the product, I used GPT to generate the table below in order to consider a wider range of personas. Due to limitations in resources and budget, I was only able to interview four people in their 20s from my personal network. However, by tailoring various virtual personas to the product using GPT, I was able to gain additional insights and references.

![User2](/images/Post_11/user2.png)

<h3>Who are we designing for?</h3>
![goal](/images/Post_11/goal.png)
---
<h1>üí°Ideation</h1>
<br><br>

<h3>Low-fidelity Design Sketch</h3>
I created the initial design by drawing it by hand.

![Low-fidelity_wireframe](/images/Post_11/Low-fidelity_wireframe.jpg)


<br>
<h3>Wireframe</h3>
Based on the sketch, we created wireframes, which helped ensure the designs aligned with the intended design goals.

![Highfidelity_wireframe](/images/Post_11/High-fidelity_wireframe.png)

<br>
<h3>User Behavior Flow</h3>
<div align="center">
  <img src="/images/Post_11/flow.png" alt="flow"> 
</div>

<br>
<h3>Design Indentity</h3>
<div align="center">
  <img src="/images/Post_11/UI_Color.png" alt="UI_Color" width="80%">
</div>
 I  wanted to highlight the system‚Äôs core identity‚Äîoffering <u>a variety of selectable modes.</u> To achieve this, the overall system design was kept simple, using gray tones, black text, and a white background. However, I used distinct and vibrant colors for each mode to visually differentiate them. Each color was carefully chosen to match the concept of its corresponding mode:
* Research ‚Äî Soft Study Blue (#DCEBFF)üîµ
* Tech ‚Äî Mint Logic Green (#E3FCEF)üü¢
* Creative ‚Äî Pastel Neon Purple (#F4E8FF)üü£
* Business ‚Äî Warm Office Orange (#FFE9CC)üü†
* Counselor ‚Äî Soft Emotional Pink (#FFE5F0)üíó 
<br><br>

Lastly, the logo combines these five colors into a single wave, forming the shape of a brain to symbolize the mind.


---
<h1>üîÅIteration</h1>
<br>

<h3>Feedback from users</h3>
Based on feedback that it should be easier to modify default settings, I added a ‚Äú...‚Äù button that allows users to easily navigate to the settings page.

![Iteration1](/images/Post_11/Iteration1.png) 

<h3>Feedback from GPT</h3>
While trying to achieve the design goal of clearly identifying user needs without overwhelming them, GPT suggested a method: providing clickable choice examples to allow users to respond easily and effortlessly.

![Iteration2](/images/Post_11/Iteration2.png) 

<h3>Feedback from Figma AI</h3>
One convenient aspect of Figma AI is that, for non-core design elements‚Äîsuch as a general settings page‚Äîit can automatically generate layouts based on common design conventions.

![Iteration3](/images/Post_11/Iteration3.png) 


<h3>Before-and-after comparison</h3>
I primarily used GPT for logo creation, refining design goals, and establishing the overall structure, while Figma AI was used for adjusting smaller aesthetic elements.

![Iteration4](/images/Post_11/Iteration4.png) 


---
<h1>‚ú®Reflection</h1>
<br>
<div style="display: flex; gap: 20px; align-items: flex-start;">
  <div style="flex: 1; text-align: center;">
    <img src="/images/Post_11/AI_use.gif" 
         alt="Project Image" 
         style="width: 100%; max-width: 450px; border-radius: 8px;">
  </div>
  <div style="flex: 2; text-align: justify;">
    <h3>Use of Artificial Intelligence</h3>
    <p>
      The goal of this course was to successfully complete a project by appropriately utilizing AI. 
      For this project, I used <strong>GPT-5, Figma Pro, and Whyser</strong> (an interview research tool). 
      In chronological order, I began by conducting interviews with four individuals to explore the potential significance 
      and necessity of the project. During this process, I used Whyser and ChatGPT to generate appropriate interview 
      questions and summarize the interview content.
      Next, I collaborated with ChatGPT for brainstorming to sketch out the initial design structure. 
      Based on this, I created wireframes using Figma. 
      While doing so, I also used ChatGPT to develop concrete user scenarios to include in the wireframes.
      <br><br>
      Finally, I used Figma AI‚Äîone of the main tools in this project‚Äîto implement dynamic interactions. 
      Since the goal of my project was to simulate a generative AI system, I aimed to produce higher-fidelity, dynamic 
      wireframes using Figma‚Äôs built-in AI capabilities.
      <br><br>
      <u>The left screen shows the use of Figma AI, where I interacted using Korean, my first language.</u>
    </p>
  </div>
</div>

![gpt uses](/images/Post_11/chatgpt.gif) 
* <strong>Figma AI</strong>: Implemented <u>interactive design elements</u>, modified aesthetic elements, and automatically designed peripheral elements. 
* <strong>ChatGPT</strong>: Helped develop core ideas, design wireframes, generate icons (using image generation tools), and suggest key revisions. 



<h3>Challenges</h3>
Since it was my first time actually designing a UI, the process felt unfamiliar, and I was not confident using Figma.  As a result, I treid to use varioius types of AI models throughout the project. In particular, although Figma AI is very useful, when designing multi-layered pages, the request can sometimes be applied to the wrong page if the specific page is not clearly mentioned by me. (This can happen even when the request is made within a certain screen, but the changes are reflected in a different one.)

<h3>Future Work</h3>
My personal research goal is to design and develop human-centered systems. In most research, this mostly involves analyzing user behavior or fine-tuning algorithms. However, in order to experiment with systems withh human subjects through mock systems, I believe it is essential to also have experience in UX/UI design and implementation. That is why I undertook this project. In the future, I will focus on improving algorithms and enhancing the quality of information. Once the design goals can be implemented algorithmically, I plan to use the experience gained from this project to guide the development of more effective system designs.


<br><br><br>