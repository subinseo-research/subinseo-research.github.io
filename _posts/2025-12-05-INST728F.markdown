---
layout: post
title:  "MindFlex AI"
date:   2025-12-5 18:05:55 +0300
image:  post_11_0.png
tags:   Human-Centered System    
---

<div style="text-align: justify;">
<h3>üîçProject Context</h3>
<p>MindFlex AI is an adaotive information system powered by gnerative AI models, which can provide personalized information and adjust their UI based on users' queries.  Therefore, it is an intelligent system in which AI reads the emotional state of the human user and responds flexibly accordingly.
<br><br>
Jensen Huang, the CEO of NVIDIA,<a href="https://www.instagram.com/reel/DR4QwDcDIVd/" target="_blank"> describes AI as the easiest tool</a> in human history and one that can help realize equity. I agree with this to some extent. More precisely, I believe that while AI is not yet such a tool, it holds that potential. Users can interact with AI through a simple chat in their preferred language, which has contributed to the rapid popularity of models like ChatGPT and Gemini. However, despite the wide diversity in users' backgrounds and contexts, these general-purpose AI models provide the same environment to all users. As a result, the quality of AI responses can vary significantly depending on users' literacy and metacognitive abilities. To address this disparity, I propose an adaptive system that reflects users' context with the UI components. 
<br><br>
This project was proposed in the course INST728F in 2025 Fall semester, led by Professor Tom Brinck at the University of Maryland, and the primary focus was to implement these ideas through UX/UI design.
</p> 
</div>

---
<div style="text-align: justify;">
    <br>
    <h3>‚ùìProblem</h3>
    Most AI systems have been optimized primarily for <u>accurcay-related metrics</u> such as F-meaurse. However, real human information-seeking behavior is far more influenced by the context in which the system is used and by psychological factors such as cognitive load and trust calibration. 
    <br><br>
    Misuse of general-purpose AI can lead to truly dangerous consequences. <a href="https://www.instagram.com/reel/DR4QwDcDIVd/" target="_blank"> In August 2025, there was a case in which a student died by suicide after interacting with ChatGPT </a>. This incident occurred, in part, because generative AIs like ChatGPT are generally designed to respond supportively to users regardless of the purpose of use. However, this issue cannot simply be dismissed as an individual's poor judgment. To design safer and more equitable information systems, we must confront and address these challenges directly.
    <br><br>
    Therefore, this project explores what kinds of design are needed to prevent misuse and build a safer information system.
    <br><br>
    <div class="notice--blue">
    "How can I reduce users' <strong>cognitive, emotional, and informational misuse</strong> in general-purpose AI?"
    </div>
    <br>
</div>

---
<h3>üéØDesogm Goals and Final Solutions</h3>

<br>
<br>
<strong>Design Goal 1Ô∏è‚É£: Support for various modes tailored to users needs</strong>
![Mainstream GIF](/images/Post_11/MainStream.gif)
* Support for five distinct modes:<br> 
            research, development, creation, business, and counseling
* The settings page allows for more specific customization 
            : preferred sources, citation style, level of alerts 
<br>
![Mainpage1GIF](/images/Post_11/Mainstream2gif)
Users can choose the best-fit mode through conversation
<br>
![Mainpage1GIF](/images/Post_11/Mainstream2gif)


<br>
<strong>Design Goal 2Ô∏è‚É£: Guide users to identify their specific information needs</strong>
![Function1 GIF](/images/Post_11/Function1.gif)
If a user submits an overly broad prompt, the system asks follow-up questions to better serve the user's ultimate needs. However, <u>to prevent users from feeling burdened by answering these questions, the design allows for quick and easy responses through clickable options.</u>

<br>
<strong>Design Goal 3Ô∏è‚É£: Build user trust in sources</strong>
![Function2 GIF](/images/Post_11/Function2.gif)
Many recent generative AI services already provide source citations. However, I added a citation type selection button so that users can easily copy and view citations at once, while also presenting an overall credibility message to encourage users' metacognitive judgment.
<br>
For credibility message, 
* If the number of sources in a generated response is between 0 and 2, the system issues a warning that the content may be dangerous üî¥
* If the number of sources is between 3 and 5, the system issues a warning that the information may be insufficient üü°
* If the number of sources is 6 or more, the system indicates that the information is safe üü¢


<br>
<strong>Design Goal 4Ô∏è‚É£: Detect Overtrust</strong>
![Function3 GIF](/images/Post_11/Function3.gif)



---
 <h1>Discovery</h1>
 <br><br>

<div align="center">
  <img src="/images/Post_11/interview.png" alt="Mainstream GIF">
  4 Interviews 
</div>


 <h3>üíÅüèª‚Äç‚ôÄÔ∏èUser study</h3>

---
 <h1>Discovery</h1>
 <br><br>



 ---
 <h1>üí°Reflection</h1>
 <br><br>


Who are we designing for?



